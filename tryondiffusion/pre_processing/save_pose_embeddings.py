# This file saves pose embeddings. These pose embeddings will be used
# for training of the parallel U_Net later.

import torch
from torch.utils.data import DataLoader

import os


def load_model(network, inp_size, model_path):
    """
    Network to load the embedding model. Removing decoder from forward pass.
    :param network: Network defined in /pose_dir/network.py.
    :param inp_size: input size for the network.
    :param model_path: path of saved model for autoencoder.
    :return: Weight loaded encoder network.
    """
    class EmbeddingNetwork(network):
        def forward(self, x):
            embeddings = self.encoder(x)
            return embeddings

    net = EmbeddingNetwork(inp_size)
    net.load_state_dict(torch.load(model_path))
    return net


def save_embeddings(dataset_class, network, inp_size, model_path, dataset_dir, save_folder):
    """
    Function to save embeddings generated by autoencoder at bottelneck of dimension 8.
    :param dataset_class: DatasetLoader defined in /pose_dir/dataloader.py.
    :param network: Network defined in /pose_dir/network.py.
    :param inp_size: input size for the network.
    :param model_path: path of saved model for autoencoder.
    :param dataset_dir: directory of dataset created by using pose keypoints.
    :param save_folder: path to save embeddings.
    :return: None.
    """
    data = dataset_class(dataset_dir)
    dataloader = DataLoader(data, batch_size=1)
    model = load_model(network, inp_size, model_path)

    # ToDo: make file_name extraction configurable
    for keypoints, json_name in dataloader:
        embeddings = model(keypoints)
        file_name = json_name[0].split("/")[-1][:8] + ".pt"
        torch.save(embeddings[0], os.path.join(save_folder, file_name))
        # print(embeddings, file_name)
        # break


if __name__ == "__main__":
    from human_pose_embedding.network import AutoEncoder as HumanAutoEncoder
    from garment_pose_embedding.network import AutoEncoder as GarmentAutoEncoder

    from human_pose_embedding.utils.dataloader import KeypointDataset as HumanKeypointDataset
    from garment_pose_embedding.utils.dataloader import KeypointDataset as GarmentKeypointDataset

    # define variables for the dataset to be processed(to get embeddings) and the network they are to be processed from.

    human_args = {"dataset_class": HumanKeypointDataset,
                  "network": HumanAutoEncoder,
                  "inp_size": 50,
                  "model_path": "./human_pose_embedding/model/best_model.pth"}

    garment_args = {"dataset_class": GarmentKeypointDataset,
                    "network": GarmentAutoEncoder,
                    "inp_size": 20,
                    "model_path": "./garment_pose_embedding/model/best_model.pth"}

    human_garment = "garment_args"
    data_folder_name = "garment_pose_embedding"
    train_test = "test"

    # path to keypoint dataset generated by notebooks "human_pose_embeddings_preproc.ipynb" and
    # "garment_pose_embeddings_preproc.ipynb"
    dataset_dir = f"./{data_folder_name}/data/{train_test}"

    # os.mkdir(f"./{data_folder_name}/embeddings")
    os.mkdir(f"./{data_folder_name}/embeddings/{train_test}_embeddings")
    save_folder = f"./{data_folder_name}/embeddings/{train_test}_embeddings"

    save_embeddings(**eval(human_garment), dataset_dir=dataset_dir, save_folder=save_folder)




